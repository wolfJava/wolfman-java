## 锁

### 一 同步锁

我们知道，锁是用来控制多个线程访问共享资源的方式，一般来说，一个锁能够防止多个线程同时访问共享资源，
在Lock接口出现之前，Java应用程序只能依靠synchronized关键字来实现同步锁的功能，在java5以后，增加了JUC 的并发包且提供了 Lock 接口用来实现锁的功能，它提供了与synchroinzed关键字类似的同步功能，只是它比
synchronized更灵活，能够显示的获取和释放锁。

### 二 Lock 的初步使用

Lock是一个接口，核心的两个方法lock和unlock，它有很多的实现，比如ReentrantLock、 ReentrantReadWriteLock。 

#### 1 ReentrantLock

重入锁，表示支持重新进入的锁，也就是说，如果当前线程t1通过调用lock方法获取了锁之后，再次调用lock，是
不会再阻塞去获取锁的，直接增加重试次数就行了。

~~~java
public class ReentrantLockDemo {
  private static int count = 0;
  static Lock lock = new ReentrantLock();
  public static void inc() {
    lock.lock();
    try {
      Thread.sleep(1);
    } catch (InterruptedException e) {
      e.printStackTrace();
    }
    count++;
    lock.unlock();
  }
  public static void main(String[] args) throws InterruptedException {
    for (int i = 0; i < 1000; i++) {
      new Thread(() -> {
        ReentrantLockDemo.inc();
      }).start();
      ;
    }
    Thread.sleep(3000);
    System.out.println("result:" + count);
  }
}
~~~

#### 2 ReentrantReadWriteLock

我们以前理解的锁，基本都是排他锁，也就是这些锁在同一时刻只允许一个线程进行访问，而读写所在同一时刻可
以允许多个线程访问，但是在写线程访问时，所有的读线程和其他写线程都会被阻塞。读写锁维护了一对锁，一个
读锁、一个写锁; 一般情况下，读写锁的性能都会比排它锁好，因为大多数场景读是多于写的。在读多于写的情况
下，读写锁能够提供比排它锁更好的并发性和吞吐量。

~~~java
public class ReentrantReadWriteLockDemo {
  static Map<String,Object> cacheMap=new HashMap<>();
  static ReentrantReadWriteLock rwl=new ReentrantReadWriteLock();
  static Lock read=rwl.readLock();
  static Lock write=rwl.writeLock();
  public static final Object get(String key) {
    System.out.println("开始读取数据"); read.lock(); //读锁
    try {
      return cacheMap.get(key);
    }finally {
      read.unlock();
    }
  }
  public static final Object put(String key,Object value){
    write.lock(); System.out.println("开始写数据"); try{
      return cacheMap.put(key,value);
    }finally {
      write.unlock();
    }
  }
}
~~~

在这个案例中，通过hashmap来模拟了一个内存缓存，然后使用读写所来保证这个内存缓存的线程安全性。当执 行读操作的时候，需要获取读锁，在并发访问的时候，读锁不会被阻塞，因为读操作不会影响执行结果。 

在执行写操作是，线程必须要获取写锁，当已经有线程持有写锁的情况下，当前线程会被阻塞，只有当写锁释放以
后，其他读写操作才能继续执行。使用读写锁提升读操作的并发性，也保证每次写操作对所有的读写操作的可见性。

> 读锁与读锁可以共享
>
> 读锁与写锁不可以共享(排他)
>
> 写锁与写锁不可以共享(排他)

#### 3 Lock和synchronized的简单对比

通过我们对Lock的使用以及对synchronized的了解，基本上可以对比出这两种锁的区别了。因为这个也是在面试 过程中比较常见的问题。

- 从层次上，一个是关键字、一个是类， 这是最直观的差异 
- 从使用上，lock具备更大的灵活性，可以控制锁的释放和获取; 而synchronized的锁的释放是被动的，当出现 异常或者同步代码块执行完以后，才会释放锁 

- lock可以判断锁的状态、而synchronized无法做到
- lock可以实现公平锁、非公平锁; 而synchronized只有非公平锁 

#### 4 AQS

Lock之所以能实现线程安全的锁，主要的核心是 AQS(AbstractQueuedSynchronizer)，AbstractQueuedSynchronizer 提供了一个 FIFO 队列，可以看做是一个用来实现锁以及其他需要同步功能的框架。这里简称该类为 AQS。AQS 的使用依靠继承来完成，子类通过继承自AQS并实现所需的方法来管理同步状态。例如常见的ReentrantLock，CountDownLatch等AQS的两种功能。

从使用上来说，AQS的功能可以分为两种：独占和共享。 独占锁模式下，每次只能有一个线程持有锁，比如前面给大家演示的 ReentrantLock 就是以独占方式实现的互斥锁。共享锁模式下，允许多个线程同时获取锁，并发访问共享资源，比如ReentrantReadWriteLock。 

很显然，独占锁是一种悲观保守的加锁策略，它限制了读/读冲突，如果某个只读线程获取锁，则其他读线程都只 能等待，这种情况下就限制了不必要的并发性，因为读操作并不会影响数据的一致性。共享锁则是一种乐观锁，它 放宽了加锁策略，允许多个执行读操作的线程同时访问共享资源 

### 三 AQS的内部实现

同步器依赖内部的同步队列(一个FIFO双向队列)来完成同步状态的管理，当前线程获取同步状态失败时，同步器会将当前线程以及等待状态等信息构造成为一个节点(Node)并将其加入同步队列，同时会阻塞当前线程，当同步状态释放时，会把首节点中的线程唤醒，使其再次尝试获取同步状态。 

Node的主要属性如下 ：

~~~java
static final class Node {
	int waitStatus; //表示节点的状态，包含cancelled(取消);condition 表示节点在等待condition，也就是在condition队列中
	Node prev; //前继节点
	Node next; //后继节点
	Node nextWaiter; //存储在condition队列中的后继节点 Thread thread; //当前线程
}
~~~

AQS类底层的数据结构是使用双向链表，是队列的一种实现。包括一个head节点和一个tail节点，分别表示头结点
和尾节点，其中头结点不存储Thread，仅保存next结点的引用。

![](1)

当一个线程成功地获取了同步状态(或者锁)，其他线程将无法获取到同步状态，转而被构造成为节点并加入到同
步队列中，而这个加入队列的过程必须要保证线程安全，因此，同步器提供了一个基于CAS的设置尾节点的方法：compareAndSetTail(Node expect,Nodeupdate)，它需要传递当前线程“认为”的尾节点和当前节点，只有设置成功后，当前节点才正式与之前的尾节点建立关联。 

![](2)

同步队列遵循FIFO，首节点是获取同步状态成功的节点，首节点的线程在释放同步状态时，将会唤醒后继节点，而后继节点将会在获取同步状态成功时将自己设置为首节点。

![](3)

设置首节点是通过获取同步状态成功的线程来完成的，由于只有一个线程能够成功获取到同步状态，因此设置头节
点的方法并不需要使用CAS来保证，它只需要将首节点设置成为原首节点的后继节点并断开原首节点的next引用即
可。

#### 1 compareAndSet

AQS中，除了本身的链表结构以外，还有一个很关键的功能，就是CAS，这个是保证在多线程并发的情况下保证线
程安全的前提下去把线程加入到AQS中的方法,可以简单理解为乐观锁。

```java
private final boolean compareAndSetHead(Node update) {
	return unsafe.compareAndSwapObject(this, headOffset, null, update);
} 
```

这个方法里面：

首先，用到了unsafe类，(Unsafe类是在sun.misc包下，不属于Java标准。但是很多Java的基础类库，包括一些被 广泛使用的高性能开发库都是基于Unsafe类开发的，比如Netty、Hadoop、Kafka等;Unsafe可认为是Java中留 下的后门，提供了一些低层次操作，如直接内存访问、线程调度等) 。

然后调用了compareAndSwapObject这个方法 ：

~~~java
public final native boolean compareAndSwapObject(Object var1, long var2, Object var4,
Object var5);
~~~

这个是一个native方法。

第一个参数为需要改变的对象，第二个为偏移量(即之前求出来的headOffset的值)，第三个参数为期待的值，第四 个为更新后的值。

整个方法的作用是如果当前时刻的值等于预期值var4相等，则更新为新的期望值 var5，如果更新成功，则返回 true，否则返回false;  

这里传入了一个headOffset，这个headOffset是什么呢?在下面的代码中，通过unsafe.objectFieldOffset

![](4)

然后通过反射获取了AQS类中的成员变量，并且这个成员变量被volatile修饰的：

~~~java
private transient volatile Node head;
private transient volatile Node tail;
private volatile int state;
~~~

#### 2 unsafe.objectFieldOffset

headOffset这个是指类中相应字段在该类的偏移量，在这里具体即是指head这个字段在AQS类的内存中相对于该类首地址的偏移量。 

一个Java对象可以看成是一段内存，每个字段都得按照一定的顺序放在这段内存里，通过这个方法可以准确地告诉
你某个字段相对于对象的起始内存地址的字节偏移。用于在后面的compareAndSwapObject中，去根据偏移量找
到对象在内存中的具体位置。

这个方法在unsafe.cpp文件中，代码如下：

~~~java
UNSAFE_ENTRY(jboolean, Unsafe_CompareAndSwapObject(JNIEnv *env, jobject unsafe, jobject
obj, jlong offset, jobject e_h, jobject x_h))
    
	UnsafeWrapper("Unsafe_CompareAndSwapObject"); 
	oop x = JNIHandles::resolve(x_h); // 新值
	oop e = JNIHandles::resolve(e_h); // 预期值 oop p = JNIHandles::resolve(obj);
	HeapWord* addr = (HeapWord *)index_oop_from_field_offset_long(p, offset);// 在内存中的 具体位置
	oop res = oopDesc::atomic_compare_exchange_oop(x, addr, e, true);// 调用了另一个方法，实 际上就是通过cas操作来替换内存中的值是否成功
	jboolean success = (res == e); // 如果返回的res等于e，则判定满足compare条件(说明res应该为 内存中的当前值)，但实际上会有ABA的问题
	if (success) // success为true时，说明此时已经交换成功(调用的是最底层的cmpxchg指令)
    	update_barrier_set((void*)addr, x); // 每次Reference类型数据写操作时，都会产生一个WriteBarrier暂时中断操作，配合垃圾收集器 
	return success;
UNSAFE_END
~~~

所以其实compareAndSet这个方法，最终调用的是unsafe类的compareAndSwap，这个指令会对内存中的共享数据做原子的读写操作。

1. 首先， cpu会把内存中将要被更改的数据与期望值做比较
2. 然后，当两个值相等时，cpu才会将内存中的对象替换为新的值。否则，不做变更操作
3. 最后，返回操作执行结果

很显然，这是一种乐观锁的实现思路。





























